---
layout: default
title: Personal Page
---

<div id="home">
  <h2><i class="fa fa-bookmark"></i> About me</h2>
  <p>I am a deep learning researcher at <a href="https://bayesgroup.ru/">Bayesian methods research group</a> 
    supervised by <a href="https://bayesgroup.ru/people/dmitry-vetrov/">Prof. Dmitry Vetrov.</a>  
    I work as a research fellow at
    <a href="https://cs.hse.ru/en/big-data/bayeslab/">Samsung AI Laboratory</a> of the 
      <a href="https://cs.hse.ru/en/">Higher School of Economics</a>. 
  At HSE, I also teach machine learning to Bachelor and Master students.
  During last three years, I've been one of the main organizers of the 
  <a href="http://deepbayes.ru/">Summer school on deep learning and Bayesian methods</a>.  </p>
  <h2><i class="fa fa-bookmark"></i> News</h2>
  <ul id="blog-posts" class="posts">
    <li><span> 10 Oct 2020 &raquo;</span> Our paper
      <a href="https://proceedings.neurips.cc/paper/2020/file/191595dc11b4d6e54f01504e3aa92f96-Paper.pdf">On Power Laws in Deep Ensembles</a> 
      was accepted as a spotlight to 
      <a href="https://neurips.cc/"> NeurIPS 2020
       </a>
    </li>
    <li><span> 11 Feb 2020 &raquo;</span> We with Ekaterina Lobacheva presented our paper
      <a href="https://ojs.aaai.org/index.php/AAAI/article/view/5938">Structured Ssparsification of Gated RNNs</a> at 
      <a href="https://aaai.org/Conferences/AAAI-20/"> AAAI Conference on Artificial Intelligence
       </a> in New York, USA (<a href="https://github.com/tipt0p/SparseGatedRNN/blob/master/slides.pdf">presentation</a>, 
      <a href="https://github.com/tipt0p/SparseGatedRNN/blob/master/poster.pdf">poster</a>)
    </li>
    <li><span> 12 Dec 2019 &raquo;</span> I presented our paper
      <a href="https://arxiv.org/abs/1911.05585">Structured sparsification of Gated RNNs</a> at 
      <a href="https://context-composition.github.io/"> NeurIPS Workshop on Context and Compositionality in Biological and Artificial Neural Systems
       </a> in Vancouver, Canada
    </li>
    <li><span> 4 Dec 2019 &raquo;</span> I gave a <a href="https://github.com/nadiinchi/bm_mini_course_UCM">lecture</a> on Bayesian neural networks at 
      <a href="https://indico.fis.ucm.es/event/13/"> Machine Learning and Applications to Physics
       </a> workshop in Madrid, Spain
    </li>
    <li><span> 25 Aug 2019 &raquo;</span> We organized the third <a href="http://deepbayes.ru/"> 
      Deep|Bayes </a> summer school.
    </li>
    <li><span> 4 Jul 2019 &raquo;</span>  I gave 
       <a href="https://github.com/yandexdataschool/mlhep2019/blob/master/slides/day-4/Bayesian/BNN.pdf"> lecture </a> 
      and  <a href="https://github.com/yandexdataschool/mlhep2019/tree/master/notebooks/day-4/Bayesian"> seminar </a> 
      on Bayesian neural networks at the 
       <a href="https://indico.cern.ch/event/768915/"> 
         Fifth Machine Learning in High Energy Physics Summer School </a> in Hamburg, Germany
    </li>
    <li><span> 26 Jun 2019 &raquo;</span>  I took part in
      Google NLP summit in Zurich, Switzerland
    </li>
    <li><span> 7 Jun 2019 &raquo;</span>  I gave a  <a href="https://github.com/nadiinchi/BayesianSparsificationTutorial"> 
      tutorial on Bayesian sparsification of neural networks </a> at  
       <a href="https://probabilistic.ai/"> 
         Probabilistic AI summer school </a> in Trondheim, Norway (<a href="https://www.youtube.com/watch?v=aW-tMXJ5a7s"> 
         video </a>)
    </li>
    <li><span> 7 Dec 2018 &raquo;</span>  I gave a contributed 
      <a href="https://github.com/tipt0p/SparseBayesianRNN/blob/master/Posters/CDNNRIA%20Workshop_presentation.pdf"> 
      talk</a> presenting our paper  <a href="https://openreview.net/forum?id=ByMQgZHYoX"> 
      Bayesian Sparsification of Gated RNNs </a> at NeurIPS 
       <a href="https://nips.cc/Conferences/2018/Schedule?showEvent=10941"> 
         Workshop on Compact Deep Neural Networks with industrial applications</a>, Montreal, Canada
    </li>
    <li><span> 3 Nov 2018 &raquo;</span>  We presented our paper  <a href="https://arxiv.org/abs/1810.10927"> 
      Bayesian Compression for Natural Language Processing </a> at 
       <a href="https://emnlp2018.org/"> EMNLP 2018</a>, Brussels, Belgium
    </li>
    <li><span>  1 Sep 2018 &raquo;</span>  We organized the second  <a href="http://deepbayes.ru/2018/"> 
      Summer school on deep learning and Bayesian methods </a> in Moscow, Russia. I was one of the main organizers
    </li>
    <li><span>  30 Aug 2017 &raquo;</span>  Our research group organized the first  <a href="http://deepbayes.ru/2017/"> 
      Summer school on deep learning and Bayesian methods</a> in Moscow, Russia. We with 
      <a href="https://www.hse.ru/en/org/persons/131072080"> 
      Kate Lobacheva </a>  ran all the organization
    </li>
    <li><span>  10 Aug 2017 &raquo;</span>  We presented our paper  <a href="https://arxiv.org/abs/1708.00077"> 
      Bayesian Sparsification of Recurrent Neural Networks </a> at 
       <a href="https://sites.google.com/site/langgen17/home"> ICML Workshop on Learning to Generate Natural Language</a>, 
      Sydney, Australia
    </li>
    <li><span>  14 Oct 2016 &raquo;</span>  Our paper <a href="http://jmlda.org/papers/doc/2016/no2/Chirkova2016hARTM.pdf"> 
      Additive regularization for hierarchical multimodal topic modeling</a> was published in 
       <a href="http://jmlda.org/"> Journal on machine learning and data analysis</a>. I gave a 
      <a href="http://www.machinelearning.ru/wiki/images/d/dc/2.Chirkova.pdf">talk</a> presenting it at the
      <a href="http://mmro.ru/en/2016/04/15/iip-11-il-en/"> 11th International Conference on Intelligent Data Processing</a> 
      in Barcelona, Spain
      
    </li>
  </ul>
</div>
